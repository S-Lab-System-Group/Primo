{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a01a1a-2e09-447a-81fb-441e0b3ac630",
   "metadata": {},
   "source": [
    "## Primo + Clara-CP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9c027",
   "metadata": {},
   "source": [
    "### Clara-CP Original Model (Pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "X, Y = pd.read_pickle(\"training.pickle\")\n",
    "X_test, Y_test = pd.read_pickle(\"testing.pickle\")\n",
    "X_actual, Y_actual = pd.read_pickle(\"nf.pickle\")\n",
    "\n",
    "# parameters\n",
    "tf.reset_default_graph()\n",
    "HIDDEN_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHES = 30\n",
    "BATCH_SIZE = 256\n",
    "SENTENCE_LIMIT_SIZE = 70\n",
    "EMBEDDING_SIZE = 64\n",
    "source_vocab_size = 125\n",
    "encoder_embedding_size = 64\n",
    "rnn_size = 64\n",
    "rnn_num_layers = 1\n",
    "\n",
    "# lstm-fc model\n",
    "print(\"initiate lstm-fc model\")\n",
    "with tf.name_scope(\"rnn\"):\n",
    "\n",
    "    with tf.name_scope(\"placeholders\"):\n",
    "        inputs = tf.placeholder(dtype=tf.int32, shape=(None, SENTENCE_LIMIT_SIZE), name=\"inputs\")\n",
    "        targets = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"targets\")\n",
    "\n",
    "    # embeddings\n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "\n",
    "        # embedding_matrix = tf.Variable(initial_value=static_embeddings, trainable=False, name=\"embedding_matrix\")\n",
    "        # embed = tf.nn.embedding_lookup(embedding_matrix, inputs, name=\"embed\")\n",
    "        encoder_embed = tf.contrib.layers.embed_sequence(inputs, source_vocab_size, encoder_embedding_size)\n",
    "\n",
    "        # sum_embed = tf.reduce_sum(encoder_embed, axis=1, name=\"sum_embed\")\n",
    "    # model\n",
    "\n",
    "    with tf.name_scope(\"model\"):\n",
    "\n",
    "        # lstm = tf.contrib.rnn.LSTMCell(HIDDEN_SIZE, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=123))\n",
    "\n",
    "        # drop_lstm = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=KEEP_PROB)\n",
    "        # _, lstm_state = tf.nn.dynamic_rnn(drop_lstm, encoder_embed, dtype=tf.float32)\n",
    "        def get_lstm(rnn_size):\n",
    "            lstm = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=123))\n",
    "            return lstm\n",
    "\n",
    "        lstms = tf.contrib.rnn.MultiRNNCell([get_lstm(HIDDEN_SIZE) for _ in range(rnn_num_layers)])\n",
    "        _, lstm_state = tf.nn.dynamic_rnn(lstms, encoder_embed, dtype=tf.float32)\n",
    "\n",
    "        W = tf.Variable(tf.truncated_normal((HIDDEN_SIZE, 1), mean=0.0, stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.zeros(1), name=\"b\")\n",
    "\n",
    "        logits = tf.add(tf.matmul(lstm_state[0].h, W), b)\n",
    "        outputs = tf.nn.sigmoid(logits, name=\"outputs\")\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "        # loss = tf.losses.mean_squared_error(targets, outputs)\n",
    "    # optimizer\n",
    "    with tf.name_scope(\"optimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "    # evaluation\n",
    "    with tf.name_scope(\"evaluation\"):\n",
    "        correct_preds = tf.equal(tf.cast(tf.greater(outputs, 0.5), tf.float32), targets)\n",
    "        accuracy = tf.reduce_sum(tf.reduce_sum(tf.cast(correct_preds, tf.float32), axis=1))\n",
    "\n",
    "\n",
    "def get_batch(x, y, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    assert x.shape[0] == y.shape[0], print(\"error shape!\")\n",
    "    # shuffle\n",
    "    if shuffle:\n",
    "        shuffled_index = np.random.permutation(range(x.shape[0]))\n",
    "\n",
    "        x = x[shuffled_index]\n",
    "        y = y[shuffled_index]\n",
    "\n",
    "    n_batches = int(x.shape[0] / batch_size)\n",
    "\n",
    "    for i in range(n_batches - 1):\n",
    "        x_batch = x[i * batch_size : (i + 1) * batch_size]\n",
    "        y_batch = y[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "        yield x_batch, y_batch\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "import time\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"./baselines/models/lstm_final\")\n",
    "    # writer = tf.summary.FileWriter(\"./graphs/lstm_final\", tf.get_default_graph())\n",
    "    n_batches = int(X.shape[0] / BATCH_SIZE)\n",
    "    print(\"n_batches: \", n_batches)\n",
    "    total_ind = 0\n",
    "    end_flag = 0\n",
    "    test_sum = 0\n",
    "    t_batches = int(X_test.shape[0] / BATCH_SIZE)\n",
    "    for x_batch, y_batch in get_batch(X_test, Y_test):\n",
    "        answer = sess.run(outputs, feed_dict={inputs: x_batch, targets: y_batch})\n",
    "        for index in range(len(answer)):\n",
    "            test_sum += (abs(answer[index] * 64 - y_batch[index] * 64)) / (y_batch[index] * 64)\n",
    "    answer = sess.run(outputs, feed_dict={inputs: X_test[-1:], targets: Y_test[-1:]})\n",
    "    # print(answer, Y_test[-1])\n",
    "    # lstm_test_accuracy.append(test_sum/(256*(t_batches-1)))\n",
    "    real_sum = 0\n",
    "    r_batches = int(X.shape[0] / BATCH_SIZE)\n",
    "    for x_batch, y_batch in get_batch(X, Y):\n",
    "        answer = sess.run(outputs, feed_dict={inputs: x_batch, targets: y_batch})\n",
    "        for index in range(len(answer)):\n",
    "            real_sum += (abs(answer[index] * 64 - y_batch[index] * 64)) / (y_batch[index] * 64)\n",
    "    # lstm_real_accuracy.append(real_sum/(256*(r_batches-1)))\n",
    "\n",
    "    answer = sess.run(outputs, feed_dict={inputs: X_actual, targets: Y_actual})\n",
    "    summation = 0\n",
    "    jndex = 0\n",
    "    pos = 0\n",
    "    nfs = [\"aggcounter\", \"anonipaddr\", \"forcetcp\", \"tcp_gen\", \"tcpack\", \"tcpresp\", \"timefilter\", \"udpipencap\"]\n",
    "    len_nfs = [15, 5, 17, 15, 2, 19, 12, 4]\n",
    "    nn = a = b = c = 0\n",
    "    temp_list = []\n",
    "    for index in range(89):\n",
    "        a += answer[index]\n",
    "        b += Y_actual[index]\n",
    "        c += abs(answer[index] - Y_actual[index])\n",
    "        summation += abs(answer[index] - Y_actual[index]) / Y_actual[index]\n",
    "        nn += abs(answer[index] - Y_actual[index]) / Y_actual[index]\n",
    "        if len_nfs[pos] > 1:\n",
    "            len_nfs[pos] -= 1\n",
    "        else:\n",
    "            temp_var = c / a\n",
    "            temp_list.append(temp_var[0])\n",
    "            pos += 1\n",
    "            a = b = c = nn = 0\n",
    "    print(\"Performance on real Click elements: \")\n",
    "    for index, item in enumerate(temp_list):\n",
    "        print(f\"WMAPE of: {nfs[index]} \\t {item}\")\n",
    "    print(f\"Average WMAPE on real NFs: {np.mean(temp_list)}\")\n",
    "    time_start = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a23dc",
   "metadata": {},
   "source": [
    "### Primo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from primo.model import PrimoRegressor\n",
    "\n",
    "\"\"\"For fast result reprodcution, we disable HPO and model selection. Use specific model type and configuration.\"\"\"\n",
    "\n",
    "feature_types = [\"categorical\"] * 70\n",
    "config = {\"learning_rate\": 0.1, \"interactions\": 150, \"feature_types\": feature_types}\n",
    "pram = PrimoRegressor(model=\"PrAM\", model_config=config, hpo=None)\n",
    "pram.fit(X, Y)\n",
    "answer = pram.predict(X_actual)\n",
    "\n",
    "'''Real NFs'''\n",
    "summation = 0\n",
    "jndex = 0\n",
    "pos = 0\n",
    "nfs = [\"aggcounter\", \"anonipaddr\", \"forcetcp\",  \"tcp_gen\", \"tcpack\", \"tcpresp\", \"timefilter\",\"udpipencap\"]\n",
    "len_nfs = [15, 5, 17, 15, 2, 19, 12, 4] \n",
    "nn = a = b = c = 0\n",
    "temp_list = []\n",
    "for index in range(89):\n",
    "    a += answer[index]\n",
    "    b += Y_actual[index]\n",
    "    c += abs(answer[index]-Y_actual[index])\n",
    "    summation += abs(answer[index]-Y_actual[index])/Y_actual[index]\n",
    "    nn += abs(answer[index]-Y_actual[index])/Y_actual[index]\n",
    "    if len_nfs[pos] > 1:\n",
    "        len_nfs[pos] -= 1\n",
    "    else:\n",
    "        temp_var = c/a\n",
    "        temp_list.append(temp_var[0])\n",
    "        pos += 1\n",
    "        a = b = c = nn = 0\n",
    "\n",
    "\n",
    "print(\"Performance on real Click elements: \")\n",
    "for index, item in enumerate(temp_list):\n",
    "    print(f\"WMAPE of: {nfs[index]} \\t {item}\")\n",
    "print(f\"Average WMAPE on real NFs: {np.mean(temp_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf96340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "220ec35765b29755edcb2bebb81fcd0a7cd14de4fe69e028c30e7300de3e2819"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tf2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
